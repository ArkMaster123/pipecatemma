# ğŸ™ï¸ Emma AI Voice Assistant

A cutting-edge **speech-to-speech AI assistant** powered by OpenAI's Realtime API with stunning real-time shader visualizations that respond to voice activity.

![Emma AI Demo](https://img.shields.io/badge/Status-Live-brightgreen) ![OpenAI Realtime](https://img.shields.io/badge/OpenAI-Realtime%20API-blue) ![WebRTC](https://img.shields.io/badge/WebRTC-Enabled-orange)

## âœ¨ Features

### ğŸ—£ï¸ **Real-Time Voice Interaction**
- **Speech-to-Speech**: Direct voice conversation with Emma AI
- **Low Latency**: WebRTC connection for minimal delay
- **Voice Activity Detection**: Automatic speech detection with server VAD
- **Natural Conversations**: Handles interruptions and maintains context

### ğŸ¨ **Stunning Visual Experience**
- **Real-Time Shader Animations**: Beautiful WebGL shaders that respond to voice
- **Voice-Reactive Visuals**: Animations change based on:
  - Your voice volume and frequency
  - Emma's response activity
  - Connection status
- **Smooth Transitions**: Fluid animations with exponential smoothing
- **Dynamic Intensity**: Visual feedback adapts to conversation flow

### ğŸ”§ **Advanced Audio Processing**
- **Frequency Analysis**: Real-time FFT analysis of audio streams
- **Voice Detection**: Smart algorithms to detect human speech patterns
- **Dual Audio Monitoring**: Analyzes both input (your voice) and output (Emma's voice)
- **Audio Quality Controls**: Echo cancellation, noise suppression, auto-gain

### ğŸ›¡ï¸ **Enterprise-Grade Security**
- **Ephemeral Tokens**: Secure session management with auto-expiring keys
- **Server-Side API Keys**: Your OpenAI keys never leave the server
- **Robust Error Handling**: Comprehensive error recovery and user feedback

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+ 
- OpenAI API key with Realtime API access
- Modern web browser with WebRTC support

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd emma-voice-assistant
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Set up environment variables**
   ```bash
   cp .env.local.example .env.local
   ```
   
   Add your OpenAI API key to `.env.local`:
   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   ```

4. **Run the development server**
   ```bash
   npm run dev
   ```

5. **Open your browser**
   Navigate to `http://localhost:3000/emma-advanced`

## ğŸ® How to Use

### ğŸ”Œ **Connect to Emma**
1. Click the **"Connect"** button
2. Allow microphone permissions when prompted
3. Wait for the connection status to show "Connected"

### ğŸ¤ **Start Talking**
- Emma automatically listens when connected
- The shader box will animate based on your voice
- Green pulsing ring indicates you're speaking
- Purple pulsing ring shows Emma is responding

### ğŸ›ï¸ **Controls**
- **ğŸ¤ Mic Button**: Toggle microphone on/off
- **ğŸ”Š Volume Button**: Mute/unmute Emma's responses  
- **ğŸ“ Disconnect Button**: End the session

### ğŸ“ **View Transcript**
- Real-time conversation transcript appears below
- Shows both your words and Emma's responses
- Timestamps for each interaction

## ğŸ—ï¸ Architecture

### ğŸ”„ **Connection Flow**
```
Frontend â†’ Backend API â†’ OpenAI Realtime API
    â†“         â†“              â†“
WebRTC â† Ephemeral Token â† Session Creation
```

### ğŸµ **Audio Processing Pipeline**
```
Microphone â†’ Web Audio API â†’ Frequency Analysis â†’ Shader Animation
                â†“
            WebRTC Stream â†’ OpenAI Realtime API
                                    â†“
Speaker â† Audio Element â† WebRTC Response â† Emma's Voice
    â†“
Shader Animation â† Output Analysis â† Audio Monitoring
```

### ğŸ“ **Project Structure**
```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/emma/realtime/          # Backend API endpoints
â”‚   â”‚   â”œâ”€â”€ session/                # Session management
â”‚   â”‚   â”œâ”€â”€ connect/                # WebRTC connection
â”‚   â”‚   â””â”€â”€ disconnect/             # Session cleanup
â”‚   â””â”€â”€ emma-advanced/              # Main voice interface
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/                         # UI components
â”‚   â””â”€â”€ ShaderBackground.tsx        # WebGL shader renderer
â”œâ”€â”€ types/                          # TypeScript definitions
â””â”€â”€ hooks/                          # Custom React hooks
```

## ğŸ”§ Technical Details

### ğŸŒ **WebRTC Implementation**
- Direct peer connection to OpenAI's Realtime API
- Automatic ICE candidate handling
- Data channels for event communication
- Media stream management for audio I/O

### ğŸ¨ **Shader System**
- WebGL-based real-time rendering
- Responds to audio frequency data
- Multiple animation states and transitions
- Optimized for 60fps performance

### ğŸ“Š **Audio Analysis**
- **FFT Size**: 256 bins for frequency analysis
- **Smoothing**: 0.8 time constant for stable visuals
- **Voice Detection**: Frequency range analysis (85Hz-255Hz)
- **Real-time Processing**: 60fps analysis loop

### ğŸ” **Security Features**
- Ephemeral API tokens (1-minute expiration)
- Server-side API key management
- Input validation and sanitization
- Comprehensive error handling

## ğŸ¯ **API Endpoints**

### `POST /api/emma/realtime/session`
Creates a new voice session with ephemeral token
- **Input**: Voice settings (voice, instructions, temperature)
- **Output**: Session ID, expiration, client secret

### `POST /api/emma/realtime/connect`
Establishes WebRTC connection (fallback endpoint)
- **Input**: Session ID, SDP offer
- **Output**: SDP answer

### `POST /api/emma/realtime/disconnect`
Cleanly terminates voice session
- **Input**: Session ID
- **Output**: Success confirmation

## ğŸ› ï¸ **Configuration**

### ğŸµ **Voice Settings**
```typescript
{
  voice: 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer',
  instructions: string,
  temperature: 0.0 - 2.0
}
```

### ğŸ¨ **Shader Parameters**
```typescript
{
  audioLevel: 0.0 - 1.0,      // Overall volume
  voiceActivity: 0.0 - 1.0,   // Voice-specific activity
  botSpeaking: boolean,        // Emma response state
  intensity: 0.3 - 1.5,       // Animation intensity
  speed: 0.3 - 2.0,           // Animation speed
  complexity: 0.0 - 1.0       // Visual complexity
}
```

## ğŸ› **Troubleshooting**

### Common Issues

**"Invalid or missing API key"**
- Ensure your OpenAI API key is set in `.env.local`
- Verify your key has Realtime API access

**"Microphone permission denied"**
- Allow microphone access in your browser
- Check browser security settings

**"WebRTC connection failed"**
- Ensure stable internet connection
- Try refreshing the page
- Check browser WebRTC support

**"Session creation failed"**
- Verify OpenAI API key validity
- Check OpenAI service status
- Review server console logs

## ğŸ”® **Future Enhancements**

- [ ] Multiple voice profiles
- [ ] Conversation history persistence
- [ ] Custom shader themes
- [ ] Mobile app support
- [ ] Multi-language support
- [ ] Voice training capabilities

## ğŸ¤ **Contributing**

We welcome contributions! Please see our contributing guidelines for details on:
- Code style and standards
- Pull request process
- Issue reporting
- Feature requests

## ğŸ“„ **License**

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ **Acknowledgments**

- OpenAI for the incredible Realtime API
- WebRTC community for real-time communication standards
- Three.js community for WebGL inspiration
- React and Next.js teams for the amazing frameworks

---

**Made with ğŸ’– by Vibe Coder**

*Experience the future of voice AI interaction with Emma - where technology meets artistry in perfect harmony.*